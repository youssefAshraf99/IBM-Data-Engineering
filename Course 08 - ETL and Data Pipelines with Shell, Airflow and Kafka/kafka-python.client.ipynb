{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Kafka Clients\n",
    "\n",
    "![Kafka clients](kafka-clients.png)\n",
    "\n",
    "Kafka has a distributed client-server architecture. For the server side, Kafka is a cluster with many associated servers called broker, acting as the event broker to receive, store, and distribute events. All those brokers are managed by another distributed system called ZooKeeper to ensure all brokers work in an efficient and collaborative way.\n",
    "\n",
    "Kafka uses a TCP based network communication protocol to exchange data between clients and servers\n",
    "\n",
    "For the client side, Kafka provides different types of clients such as:\n",
    "- Kafka CLI, which is a collection of shell scripts to communicate with a Kafka server\n",
    "- Many high-level programming APIs such as Python, Java, and Scala\n",
    "- REST APIs\n",
    "- Specific 3rd party clients made by the Kafka community\n",
    "You can choose different clients based on your requirements. In this reading, we will be focusing on a Kafka Python client called `kafka-python`\n",
    "\n",
    "## `kafka-python` package\n",
    "`kafka-python` is a Python client for the Apache Kafka distributed stream processing system, which aims to provide similar functionalities as the main Kafka Java client.\n",
    "\n",
    "With `kafka-python`, you can easily interact with your Kafka server such as managing topics, publish, and consume messages in Python programming language.\n",
    "\n",
    "## Install kafka-python\n",
    "Install `kafka-python` is similar to other regular Python packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "     -------------------------------------- 246.5/246.5 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see the use cases of the main functions provided by the kafka-python package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KafkaAdminClient Class\n",
    "The main purpose of `KafkaAdminClient` class is to enable fundamental administrative management operations on kafka server such as creating/deleting topic, retrieving, and updating topic configurations and so on.\n",
    "\n",
    "Let's check some concrete code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `KafkaAdminClient` object\n",
    "To use KafkaAdminClient, we first need to define and create a KafkaAdminClient object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KafkaAdminClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\CODING\\IBM DE\\ETL pipeline\\kafka-python.client.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CODING/IBM%20DE/ETL%20pipeline/kafka-python.client.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m admin_client \u001b[39m=\u001b[39m KafkaAdminClient(bootstrap_servers\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocalhost:9092\u001b[39m\u001b[39m\"\u001b[39m, client_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KafkaAdminClient' is not defined"
     ]
    }
   ],
   "source": [
    "admin_client = KafkaAdminClient(bootstrap_servers=\"localhost:9092\", client_id='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `bootstrap_servers=\"localhost:9092\"` argument specifies the host/IP and port that the consumer should contact to bootstrap initial cluster metadata\n",
    "- `client_id` specifies an id of current admin client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new topics\n",
    "Next, the most common usage of `admin_client` is managing topics such as creating and deleting topics.\n",
    "\n",
    "To create new topics, we first need to define an empty topic list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the `NewTopic` class to create a topic with name equals `bankbranch`, partition nums equals to 2, and replication factor equals to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topic = NewTopic(name=\"bankbranch\", num_partitions= 2, replication_factor=1)\n",
    "topic_list.append(new_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we can use `create_topics(...)` method to create new topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client.create_topics(new_topics=topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above create topic operation is equivalent to using kafka-topics.sh --topic in Kafka CLI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "kafka-topics.sh --bootstrap-server localhost:9092 --create --topic bankbranch  --partitions 2 --replication_factor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe a topic\n",
    "\n",
    "Once new topics are created, we can easily check its configuration details using `describe_configs()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = admin_client.describe_configs(\n",
    "    config_resources=[ConfigResource(ConfigResourceType.TOPIC, \"bankbranch\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above describe topic operation is equivalent to using kafka-topics.sh --describe in Kafka CLI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic bankbranch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KafkaProducer\n",
    "\n",
    "Now we have a new `bankbranch` topic created, we can start produce messages to the topic.\n",
    "\n",
    "For `kafka-python`, we will use `KafkaProducer` class to produce messages. Since many real-world message values are in the format of JSON, we will show you how to publish JSON messages as an example.\n",
    "\n",
    "First, let's define and create a `KafkaProducer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(value_serializer=lambda v: json.dumps(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Kafka produces and consumes messages in raw bytes, we need to encode our JSON messages and serialize them into bytes.\n",
    "\n",
    "For the `value_serializer` argument, we define a lambda function to take a Python dict/list object and serialize it into bytes.\n",
    "\n",
    "Then, with the `KafkaProducer` created, we can use it to produce two ATM transaction messages in JSON format as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\"bankbranch\", {'atmid':1, 'transid':100})\n",
    "producer.send(\"bankbranch\", {'atmid':2, 'transid':101})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument specifies the topic `bankbranch` to be sent, and the second argument represents the message value in a Python dict format and will be serialized into bytes.\n",
    "\n",
    "The above producing message operation is equivalent to using `kafka-console-producer.sh --topic` in Kafka CLI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "kafka-console-producer.sh --bootstrap-server localhost:9092 --topic bankbranch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KafkaConsumer\n",
    "\n",
    "In the previous step, we published two JSON messages. Now we can use the `KafkaConsumer` class to consume them.\n",
    "\n",
    "We just need to define and create a `KafkaConsumer` subscribing to the topic `bankbranch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer('bankbranch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the consumer is created, it will receive all available messages from the topic `bankbranch`. Then we can iterate and print them with the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in consumer:\n",
    "    print(msg.value.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above consuming message operation is equivalent to using `kafka-console-consumer.sh --topic` in Kafka CLI client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic bankbranch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this reading, you have learned how to use `kafka-python` package to perform some main operations such as create or describe topic, produce and consume messages with a Kafka server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
